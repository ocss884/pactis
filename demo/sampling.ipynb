{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F\n",
    "\n",
    "path = Path(os.path.abspath(os.curdir)).parent\n",
    "import sys\n",
    "sys.path.append(str(path))\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "from pactis.core.adapter import InputAdapter\n",
    "from pactis.core.config import LatentQueryConfig, CrossAttentionLayerConfig, SelfAttentionBlockConfig, PerceiverEncoderConfig, PerceiverDecoderConfig\n",
    "from pactis.core.encoder import PerceiverIO, PerceiverEncoder, PerceiverDecoder\n",
    "from pactis.core.decoder import AttentionalCopula, CopulaDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = AttentionalCopula(input_dim=128, attn_heads=4, attn_dim=32, attn_layers=1, mlp_dim=128, mlp_layers=2, resolution=10, dropout=0.1).to(\"cuda\")\n",
    "model.loss(torch.randn((18, 4, 10, 128), device='cuda'),\n",
    "           torch.randn((18, 4, 10), device='cuda'),\n",
    "              mask = [0, 1, 1, 1, 1, 1, 1, 0, 1, 0], device=\"cuda\")\n",
    "# model.sample(torch.randn((1, 4, 10, 128), device='cuda'),\n",
    "#              torch.randn((1, 4, 10), device='cuda'),\n",
    "#              mask = [0, 1, 1, 1, 1, 1, 1, 0, 1, 1], device=\"cuda\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "A = torch.randn((2, 4, 128), device='cuda')\n",
    "B = rearrange(torch.Tensor([1,1,float(\"-inf\"),1]), \"b -> 1 b 1\").to('cuda')\n",
    "(A * B)[1,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncoderConfig = PerceiverEncoderConfig.create_from_config(InputAdapter(256),\n",
    "                                                          LatentQueryConfig(num_latents=20,\n",
    "                                                                            num_latent_dim=64),\n",
    "                                                          CrossAttentionLayerConfig(num_heads=8,\n",
    "                                                                                    num_q_input_dim=64,\n",
    "                                                                                    num_kv_input_dim=256),\n",
    "                                                                                    # num_qk_dim=64,\n",
    "                                                                                    # num_v_dim=64),\n",
    "                                                          SelfAttentionBlockConfig(num_layers=4,\n",
    "                                                                                   num_heads=8,\n",
    "                                                                                   num_dim=64),\n",
    "                                                        num_cross_attn_layers=1,\n",
    "                                                        num_self_attn_blocks=8,\n",
    "                                                        )\n",
    "DecoderConfig = PerceiverDecoderConfig.create_from_config(LatentQueryConfig(num_latents=100,\n",
    "                                                                            num_latent_dim=256), \n",
    "                                                          CrossAttentionLayerConfig(num_heads=8,\n",
    "                                                                                  num_q_input_dim=256, \n",
    "                                                                                  num_kv_input_dim=64))\n",
    "copula = {\"attn_heads\":8, \"attn_dim\": 32, \"attn_layers\": 1, \"mlp_dim\": 128, \"mlp_layers\": 2, \"resolution\": 10, \"dropout\":0.1}\n",
    "dsf = {\"mlp_layers\": 1, \"mlp_dim\": 48, \"flow_layers\": 3, \"flow_hid_dim\": 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CopulaDecoder(input_dim = 256, attentional_copula=copula, dsf_marginal={\n",
    "                \"mlp_layers\": 1,\n",
    "                \"mlp_dim\": 48,\n",
    "                \"flow_layers\": 3,\n",
    "                \"flow_hid_dim\": 16,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = PerceiverEncoder.from_config(EncoderConfig).to(\"cuda\")\n",
    "Decoder = PerceiverDecoder.from_config(DecoderConfig).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder = PerceiverIO.from_config(EncoderConfig, DecoderConfig).to(\"cuda\")\n",
    "# Decoder = AttentionalCopula(input_dim=256, attn_heads=8, attn_dim=32, attn_layers=1, mlp_dim=128, mlp_layers=2, resolution=10, dropout=0.1).to(\"cuda\")\n",
    "Decoder = CopulaDecoder(input_dim = 256, attentional_copula=copula, dsf_marginal=dsf).to(\"cuda\")\n",
    "x = torch.randn(64, 100, 256, device='cuda')\n",
    "y = Encoder(x)\n",
    "y.shape\n",
    "# y = y.reshape(64, 10, 10, 256)\n",
    "# Decoder.sample(y, torch.randn((64, 10, 10), device='cuda'), mask = torch.Tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1]), device=\"cuda\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(torch.LongTensor((1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "optimizer = torch.optim.Adam(list(Encoder.parameters()) + list(Decoder.parameters()), lr=1e-3)\n",
    "x = torch.randn(200, 100, 256, device='cuda')\n",
    "# with torch.no_grad():\n",
    "for i in range(50):\n",
    "    x = Encoder(x)\n",
    "    x = x.repeat(1, 5, 2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceiverEncoder(\n",
       "  (latent_provider): LatentQuery()\n",
       "  (input_adapter): InputAdapter()\n",
       "  (cross_attn_1): CrossAttentionLayer(\n",
       "    (cross_attn): CrossAttention(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (k_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (v_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (o_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (kv_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn_out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (_ca_layer): Sequential(\n",
       "      (0): Residual(\n",
       "        (module): CrossAttention(\n",
       "          (attention): MultiHeadAttention(\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (k_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (o_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (module): Sequential(\n",
       "          (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (self_attn_1): SelfAttentionBlock(\n",
       "    (0): SelfAttentionLayer(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Residual(\n",
       "        (module): SelfAttention(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attention): MultiHeadAttention(\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (o_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Residual(\n",
       "        (module): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SelfAttentionLayer(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Residual(\n",
       "        (module): SelfAttention(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attention): MultiHeadAttention(\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (o_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Residual(\n",
       "        (module): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SelfAttentionLayer(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Residual(\n",
       "        (module): SelfAttention(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attention): MultiHeadAttention(\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (o_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Residual(\n",
       "        (module): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SelfAttentionLayer(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Residual(\n",
       "        (module): SelfAttention(\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attention): MultiHeadAttention(\n",
       "            (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (o_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Residual(\n",
       "        (module): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PerceiverEncoder.from_config(EncoderConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 4, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(4).repeat(2,5,1)[:, :, :, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3, 'a': 1, 'device': 'cuda'}\n"
     ]
    }
   ],
   "source": [
    "class first:\n",
    "    def __init__(self, a=None, device=None):\n",
    "        self.a = a\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "class second(first):\n",
    "    def __init__(self, b=None, **kwargs):\n",
    "        print(kwargs)\n",
    "        super().__init__(device = kwargs.get(\"device\", None))\n",
    "        # self.factory = {\"a\": self.a, \"b\": b}\n",
    "\n",
    "\n",
    "m = second(C=3, a=1, b=2, device=\"cuda\")\n",
    "m.a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AttentionalCopulaConfig:\n",
    "    input_dim: int = 15\n",
    "    attn_heads: int = 5\n",
    "    attn_dim: int = 16\n",
    "    attn_layers: int = 3\n",
    "    mlp_dim: int = 32\n",
    "    mlp_layers: int = 3\n",
    "    resolution: int = 10\n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        return asdict(self)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "config = AttentionalCopulaConfig()\n",
    "model = AttentionalCopula(**config.dict).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = torch.randn((100, 5, 20, 15), device=device)\n",
    "true_u = torch.rand((100, 5, 20), device=device, dtype=torch.float)\n",
    "print(true_u[0, :, 7:])\n",
    "mask = torch.Tensor([1]*8+[0]*3+[1]*9)\n",
    "print(model.sample(encoded, true_u, mask, device=device)[0, :, 7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.MultiheadAttention(embed_dim=15, num_heads=5, kdim=32, vdim=64, batch_first=True)\n",
    "for module in model.named_parameters():\n",
    "    print(module[0], module[1].shape)\n",
    "model(torch.randn(10, 100, 15), torch.randn(10, 100, 32), torch.randn(10, 100, 64))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pactis.model.core.modules import MultiHeadAttention\n",
    "model = MultiHeadAttention(5, 15, 20)\n",
    "model(torch.randn(1, 50, 15), torch.randn(1, 100, 20), pad_mask=torch.Tensor([[1]*99+[0]*1]).bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(nn.Sequential):\n",
    "    def forward(self, *x, **kwargs):\n",
    "        for i, module in enumerate(self):\n",
    "            if type(x) == tuple:\n",
    "                if i == 0:\n",
    "                    x = module(*x, **kwargs)\n",
    "                else:\n",
    "                    x = module(*x)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        return x\n",
    "class mdl(Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(nn.Linear(5, 10), nn.Linear(10, 15))\n",
    "model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F\n",
    "\n",
    "path = Path(os.path.abspath(os.curdir)).parent.parent\n",
    "import sys\n",
    "sys.path.append(str(path))\n",
    "\n",
    "from pactis.model.core.decoder import AttentionalCopula\n",
    "from pactis.model.core.modules import CrossAttentionLayer, Sequential, Residual\n",
    "model = CrossAttentionLayer(5, 15, 20)\n",
    "model(torch.randn(1, 50, 15), torch.randn(1, 100, 20), torch.randn(1, 100, 20)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(nn.Sequential):\n",
    "    def forward(self, *x, **kwargs):\n",
    "        for i, module in enumerate(self):\n",
    "            if type(x) == tuple:\n",
    "                if i == 0:\n",
    "                    x = module(*x, **kwargs)\n",
    "                else:\n",
    "                    x = module(*x)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MultiheadAttention\n",
    "model = MultiheadAttention(15, 5, kdim=10, vdim=20)\n",
    "MODEL = Sequential(model, nn.Linear(15, 64))\n",
    "MODEL(torch.randn(1, 100, 15), torch.randn(1, 100, 10), torch.randn(1, 100, 20))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from dataclasses import dataclass, asdict, KW_ONLY, field\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    @property\n",
    "    def dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "@dataclass\n",
    "class AConfig(Config):\n",
    "    a: int = 10\n",
    "    b: int = 20\n",
    "    _: KW_ONLY\n",
    "    c: int = 30\n",
    "    d: int = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.d = self.a + self.b\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CrossAttentionLayerConfig(Config):\n",
    "    n_heads: int\n",
    "    num_q_input_dim: int\n",
    "    num_kv_input_dim: int\n",
    "    num_qk_dim: Optional[int] = None\n",
    "    num_v_dim: Optional[int] = None\n",
    "    qkv_bias: bool = True\n",
    "    out_bias: bool = True\n",
    "    mlp_bias: bool = True\n",
    "    widening_factor: int = 1\n",
    "    dropout: float = 0.1\n",
    "    batch_first: bool = True\n",
    "    norm_first: bool = True\n",
    "    device: Optional[torch.device] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype: Optional[torch.dtype] = None\n",
    "\n",
    "config = CrossAttentionLayerConfig(5, 15, 20)\n",
    "config.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CLASS:\n",
    "    a: int = 10\n",
    "    b: int = 20\n",
    "    c: int = 30\n",
    "    d: int = field(init=False)\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.d = self.a + self.b\n",
    "        \n",
    "    @classmethod\n",
    "    def from_else(cls, a, b, c):\n",
    "        return cls(a, b, c)\n",
    "\n",
    "# MODEL = CLASS()\n",
    "MODEL = CLASS.from_else(1, 2, 3)\n",
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    _: KW_ONLY\n",
    "    device: Optional[torch.device] = None\n",
    "    dtype: Optional[torch.dtype] = None\n",
    "    @property\n",
    "    def dict(self):\n",
    "        return asdict(self)\n",
    "@dataclass\n",
    "class batch_norm_order:\n",
    "    _: KW_ONLY\n",
    "    norm_first: bool = True\n",
    "    batch_first: bool = True\n",
    "\n",
    "@dataclass\n",
    "class LatentQueryConfig(Config, batch_norm_order):\n",
    "    num_latents: int\n",
    "    num_latent_dim: int\n",
    "    init_scale: float = 0.02\n",
    "config = LatentQueryConfig(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pactis.model.core.modules import SelfAttentionBlock\n",
    "# from pactis.model.core.encoder import PerceiverEncoder, PerceiverDecoder\n",
    "from pactis.model.core.config import PerceiverEncoderConfig, PerceiverDecoderConfig\n",
    "from pactis.model.core.adapter import InputAdapter\n",
    "# config = SelfAttentionBlockConfig(5, 15, dropout=0.1, device=\"cuda\")\n",
    "# model = SelfAttentionBlock(**config.dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PerceiverEncoderConfig(InputAdapter(15, 20), 5, 16)\n",
    "PerceiverEncoder(**config.dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".base3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46e680af6c1982026ac639fc2d3cf57b97ed93ae92b2cb694c5e34d7389b6d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
